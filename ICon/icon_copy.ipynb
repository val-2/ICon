{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T09:39:30.003305Z",
     "start_time": "2024-06-22T09:39:29.921878Z"
    }
   },
   "source": [
    "import sys\n",
    "import asyncio\n",
    "\n",
    "if sys.platform == 'win32':\n",
    "    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Read the CSV file\n",
    "original_df = pd.read_csv('used_cars.csv')\n",
    "\n",
    "\n",
    "def preprocessing(df):\n",
    "    df = df.copy()\n",
    "    # Per non avere valori nulli nella colonna Service History\n",
    "    df['Service history'] = df['Service history'].fillna(\"Unavailable\")\n",
    "    df['Service history'] = df['Service history'].map({'Full': True, 'Unavailable': False})\n",
    "    # Prendere le colonne categoriche e trasformarle in colonne numeriche facendo il one-hot encoding\n",
    "    # In python gli alberi di decisione non supportano feature categoriche\n",
    "\n",
    "    # Prendere solo la marca dell'auto\n",
    "    df['title'] = df['title'].apply(lambda x: x.split()[0] if isinstance(x, str) else x)\n",
    "\n",
    "    # Abbiamo provato a togliere proprio title ma predizioni peggiori\n",
    "\n",
    "    # Eliminare la prima colonna che è l'indice\n",
    "    df = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "    # Prendi la cilindrata dell'auto e trasformala in un numero\n",
    "    df['Engine'] = df['Engine'].str.replace('L', '').astype(float)\n",
    "\n",
    "    df['Gearbox'] = df['Gearbox'].map({'Automatic': True, 'Manual': False})\n",
    "    df = df.rename(columns={'Gearbox': 'Gearbox Automatic'})\n",
    "\n",
    "    df['Emission Class'] = pd.to_numeric(df['Emission Class'].str.replace('Euro ', ''), errors='coerce')\n",
    "\n",
    "    df['Previous Owners'] = df['Previous Owners'].fillna(0)\n",
    "\n",
    "    df = df[~df['Body type'].isin([\"Combi Van\", \"Minibus\", \"Pickup\"])]\n",
    "\n",
    "    df['Fuel type'] = df['Fuel type'].apply(lambda x: {'Petrol Plug-in Hybrid': \"Electric/Hybrid\", 'Petrol Hybrid': \"Electric/Hybrid\", 'Diesel Hybrid': \"Electric/Hybrid\", \"Electric\": \"Electric/Hybrid\"}.get(x, x))\n",
    "\n",
    "    df[\"Doors\"] = df[\"Doors\"].fillna(5)\n",
    "    df[\"Seats\"] = df[\"Seats\"].fillna(5)\n",
    "\n",
    "    value_counts = df[\"title\"].value_counts()\n",
    "\n",
    "    # Filter the values that occur 10 times or more\n",
    "    values_to_keep = value_counts[value_counts >= 20].index\n",
    "\n",
    "    # Filter the DataFrame to keep only rows with the desired values\n",
    "    df = df[df[\"title\"].isin(values_to_keep)]\n",
    "\n",
    "    df.to_csv('preprocessed_data.csv', index=False)\n",
    "\n",
    "    df = pd.get_dummies(df, columns=['Fuel type', 'Body type', 'title'])\n",
    "\n",
    "    # Algoritmi necessitano di valori non nulli\n",
    "    df = df.dropna()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "preprocessed_df = preprocessing(original_df)\n",
    "target_column = \"Price\"\n",
    "# Prendere le colonne categoriche e trasformarle in colonne numeriche facendo il one-hot encoding\n",
    "# In python gli alberi di decisione non supportano feature categoriche\n",
    "\n",
    "\n",
    "print(preprocessed_df)\n",
    "\n",
    "X = preprocessed_df.drop(target_column, axis=1)\n",
    "y = preprocessed_df[target_column]\n",
    "\n",
    "# y_extracted = preprocessed_df[[target_column]]\n",
    "# scaler = MinMaxScaler()\n",
    "# y = scaler.fit_transform(y_extracted).ravel()\n",
    "\n",
    "\n",
    "..."
   ],
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "    # Apprendimento supervisionato"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T09:39:31.724661Z",
     "start_time": "2024-06-22T09:39:31.701108Z"
    }
   },
   "source": [
    "def calculate_baseline_score(df, target_column, scoring):\n",
    "    # Per vedere se la loss del modello è migliore di quella che si potrebbe ottenere con una predizione banale, come media o mediana\n",
    "    if scoring == \"neg_root_mean_squared_error\":\n",
    "        baseline_prediction = df[target_column].mean()\n",
    "        baseline_error = - (df[target_column] - baseline_prediction).pow(2).mean() ** 0.5\n",
    "    elif scoring == \"neg_mean_absolute_error\":\n",
    "        baseline_prediction = df[target_column].median()\n",
    "        baseline_error = - (df[target_column] - baseline_prediction).abs().mean()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid scoring metric\")\n",
    "\n",
    "    return baseline_error\n",
    "\n",
    "\n",
    "def search_hyperparameters(model, param_grid, X, y, cv, scoring):\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=cv, scoring=scoring, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # scores = cross_val_score(ctf, X, y, cv=cv, scoring=scoring)\n",
    "    # grid_search.fit implicitamente usa cross_val_score e quindi non abbiamo bisogno di ripeterlo\n",
    "    # Gli score ottenuti usando cross_val_score con i migliori iperparametri sono già restituiti da grid_search\n",
    "    scores = grid_search.best_score_\n",
    "    params = grid_search.best_params_\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Best params:\", params)\n",
    "\n",
    "    model_results = {\"scores\": scores, \"params\": params, \"model\": grid_search.best_estimator_}\n",
    "\n",
    "    return model_results\n",
    "\n",
    "\n",
    "def performance_comparison(train_results):\n",
    "    for scoring_metric in train_results:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "        models = list(train_results[scoring_metric].keys())\n",
    "        scores = [train_results[scoring_metric][model][\"scores\"] for model in models]\n",
    "\n",
    "        # Extract mean scores for plotting\n",
    "        mean_scores = [np.mean(score) for score in scores]\n",
    "\n",
    "        ax.bar(models, mean_scores, color=['blue', 'green', 'red'])\n",
    "        plt.gca().invert_yaxis()\n",
    "\n",
    "        ax.set_title(f'Performance Comparison ({scoring_metric})')\n",
    "        ax.set_xlabel('Models')\n",
    "        ax.set_ylabel('Mean Score')\n",
    "\n",
    "        # Adjust y-axis limits to better visualize negative scores\n",
    "        # ymin = max(mean_scores) * 1.1 if min(mean_scores) < 0 else max(mean_scores) * 0.9\n",
    "        # ymax = min(mean_scores) * 1.1 if max(mean_scores) > 0 else min(mean_scores) * 0.9\n",
    "        # ax.set_ylim([ymin, ymax])\n",
    "        ax.grid(True)\n",
    "\n",
    "        # Adding text for each bar\n",
    "        # for i, v in enumerate(mean_scores):\n",
    "        #     if v < 0:\n",
    "        #         ax.text(i, v - (max(mean_scores) * 0.01) - 20, f\"{v:.2f}\", ha='center', va='top')\n",
    "        #     else:\n",
    "        #         ax.text(i, v + (max(mean_scores) * 0.01) - 20, f\"{v:.2f}\", ha='center', va='bottom')\n",
    "\n",
    "        plt.savefig(f\"performance_comparison_{scoring_metric}.png\")\n",
    "\n",
    "\n",
    "def show_learning_curves(search_results, X_set, y_set, cv):\n",
    "    # Initialize an empty DataFrame\n",
    "    variance_df = pd.DataFrame(columns=['Model', 'Train Score Variance', 'Test Score Variance'])\n",
    "\n",
    "    for scoring_metric in search_results:\n",
    "        for model_name in search_results[scoring_metric]:\n",
    "            title = f\"Learning Curve ({model_name}, {scoring_metric})\"\n",
    "            estimator = search_results[scoring_metric][model_name].get(\"model\", None)\n",
    "            if estimator is None:\n",
    "                continue\n",
    "\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.title(title)\n",
    "            plt.xlabel(\"Training examples\")\n",
    "            plt.ylabel(scoring_metric)\n",
    "\n",
    "            train_sizes, train_scores, test_scores = learning_curve(\n",
    "                estimator, X_set, y_set, cv=cv, n_jobs=None, train_sizes=np.linspace(0.1, 1.0, 10), scoring=scoring_metric\n",
    "            )\n",
    "\n",
    "            train_scores_mean = np.mean(train_scores, axis=1)\n",
    "            train_scores_std = np.std(train_scores, axis=1)\n",
    "            test_scores_mean = np.mean(test_scores, axis=1)\n",
    "            test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "            plt.grid()\n",
    "\n",
    "            plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                             train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "            plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                             test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "            plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "            plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "            plt.legend(loc=\"best\")\n",
    "            plt.savefig(f\"{title}.png\")\n",
    "            print(f\"Saved {title}.png\")\n",
    "\n",
    "            # Calculate the variance of the train and test scores\n",
    "            train_score_variance = np.var(train_scores, axis=1)[-1]\n",
    "            test_score_variance = np.var(test_scores, axis=1)[-1]\n",
    "\n",
    "            # Create a DataFrame with a single row of data\n",
    "            variance_data = pd.DataFrame([{\n",
    "                'Model': title,\n",
    "                'Train Score Variance': train_score_variance,\n",
    "                'Test Score Variance': test_score_variance,\n",
    "                'Ratio': test_score_variance / train_score_variance\n",
    "            }])\n",
    "\n",
    "            # Append the new data to the DataFrame\n",
    "            variance_df = pd.concat([variance_df, variance_data], ignore_index=True)\n",
    "            print(variance_df.head())\n",
    "\n",
    "    # Print the DataFrame\n",
    "    return variance_df\n",
    "\n",
    "\n",
    "# Scelte due metriche di scoring\n",
    "scorings = ['neg_root_mean_squared_error', 'neg_mean_absolute_error']\n"
   ],
   "execution_count": 42,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training dei modelli"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T09:39:48.750620Z",
     "start_time": "2024-06-22T09:39:32.828831Z"
    }
   },
   "source": [
    "results = {s: {\"decision_tree\": {},\n",
    "               \"random_forest\": {},\n",
    "               \"gradient_boosting\": {}} for s in scorings}\n",
    "\n",
    "dtr_param_grid = {\n",
    "    'criterion': [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"],\n",
    "    # 'splitter': ['best'],\n",
    "    # 'max_depth': [None, 10, 20],\n",
    "    # 'min_samples_split': [2, 5, 10, 20],\n",
    "    # 'min_samples_leaf': [1, 2, 5],\n",
    "}\n",
    "\n",
    "rfr_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    # 'criterion': [\"squared_error\", \"friedman_mse\", \"poisson\"],\n",
    "    # 'max_depth': [None, 5, 10],\n",
    "    # 'min_samples_split': [2, 5, 10, 20],\n",
    "    # 'min_samples_leaf': [1, 2, 5],\n",
    "}\n",
    "\n",
    "gbr_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    # 'loss': ['squared_error', 'huber', 'quantile'],\n",
    "    # 'learning_rate': [0.01, 0.1, 0.5],\n",
    "    # 'criterion': ['friedman_mse', 'squared_error'],\n",
    "    # 'max_depth': [None, 5, 10],\n",
    "    # 'min_samples_split': [2, 5, 10, 20],\n",
    "    # 'min_samples_leaf': [1, 2, 5],\n",
    "}\n",
    "\n",
    "# Perform 5-fold cross-validation, repeated 3 times, and print the average score\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=1)\n",
    "# TODO fonty per la grid search fa solo cv=5 che come se fosse n_repeats=1\n",
    "\n",
    "# Addestrare ogni modello per ogni metrica di scoring\n",
    "for scoring in scorings[:1]:\n",
    "    baseline_score = calculate_baseline_score(original_df, target_column, scoring)\n",
    "    print(f\"Baseline for scoring metric {scoring}: \", baseline_score)\n",
    "\n",
    "    dtr = DecisionTreeRegressor()\n",
    "    print(f\"Training decision tree with scoring metric {scoring}\")\n",
    "    results[scoring][\"decision_tree\"] = search_hyperparameters(dtr, dtr_param_grid, X, y, cv, scoring)\n",
    "\n",
    "    rfr = RandomForestRegressor()\n",
    "    print(f\"Training random forest with scoring metric {scoring}\")\n",
    "    results[scoring][\"random_forest\"] = search_hyperparameters(rfr, rfr_param_grid, X, y, cv, scoring)\n",
    "\n",
    "    gbr = GradientBoostingRegressor()\n",
    "    print(f\"Training gradient boosted model with scoring metric {scoring}\")\n",
    "    results[scoring][\"gradient_boosting\"] = search_hyperparameters(gbr, gbr_param_grid, X, y, cv, scoring)\n",
    "\n",
    "print(results)\n"
   ],
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T09:39:49.100986Z",
     "start_time": "2024-06-22T09:39:48.752631Z"
    }
   },
   "source": "performance_comparison(results)",
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T09:45:25.066433Z",
     "start_time": "2024-06-22T09:42:23.535553Z"
    }
   },
   "source": [
    "cv = RepeatedKFold(n_splits=5, n_repeats=3)\n",
    "var_df = show_learning_curves(results, X, y, cv)\n",
    "print(var_df.head())"
   ],
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprendimento non supervisionato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T18:21:37.830629Z",
     "start_time": "2024-06-04T18:21:35.573896Z"
    }
   },
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calcola la somma dei quadrati interni per diversi numeri di cluster\n",
    "wcss = []\n",
    "for i in range(1, 7):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=42)\n",
    "    kmeans.fit(X)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Crea un grafico con il numero di cluster sull'asse x e WCSS sull'asse y\n",
    "plt.plot(range(1, 7), wcss)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Somma delle distanze quadrate interne')\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T18:32:50.834198Z",
     "start_time": "2024-06-04T18:30:34.667335Z"
    }
   },
   "source": [
    "n_clusters = 3  # o 4???\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "\n",
    "# Addestra il modello sui dati\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Utilizza il modello per fare previsioni\n",
    "predictions = kmeans.predict(X)\n",
    "\n",
    "# Aggiungi le previsioni al DataFrame\n",
    "preprocessed_df['Cluster'] = predictions\n",
    "\n",
    "..."
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Riduzione della dimensionalità"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T09:54:55.027029Z",
     "start_time": "2024-06-22T09:54:54.302203Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Supponiamo che 'preprocessed_df' sia il dataframe preprocessato\n",
    "# Standardizzare i dati\n",
    "scaler = StandardScaler()\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "\n",
    "# Applicare PCA senza ridurre il numero di componenti\n",
    "pca = PCA()\n",
    "pca.fit(scaled_X)\n",
    "\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(cumulative_variance, marker='o')\n",
    "plt.xlabel('Numero di Componenti')\n",
    "plt.ylabel('Varianza Spiegata Cumulativa')\n",
    "plt.title('Varianza Spiegata Cumulativa per PCA')\n",
    "plt.axhline(y=0.95, color='r', linestyle='--')  # Linea di soglia al 95%\n",
    "plt.axhline(y=0.99, color='g', linestyle='--')  # Linea di soglia al 99%\n",
    "plt.show()\n",
    "\n",
    "num_components_95 = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "print(f'Numero di componenti che spiegano almeno il 95% della varianza: {num_components_95}')\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(pca.explained_variance_ratio_, marker='o')\n",
    "plt.xlabel('Numero di Componenti')\n",
    "plt.ylabel('Varianza Spiegata')\n",
    "plt.title('Scree Plot')\n",
    "plt.show()\n"
   ],
   "execution_count": 58,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si è deciso di prendere 8 componenti principali"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T09:55:29.747806Z",
     "start_time": "2024-06-22T09:55:29.590993Z"
    }
   },
   "source": [
    "# Applicare PCA con 8 componenti\n",
    "n_components = 7\n",
    "pca = PCA(n_components)\n",
    "pca_data = pca.fit_transform(scaled_X)\n",
    "\n",
    "# Creare un DataFrame con i dati PCA\n",
    "pca_X = pd.DataFrame(data=pca_data, columns=[f'PC{i}' for i in range(1, n_components + 1)])\n",
    "\n",
    "print(pca_X)\n"
   ],
   "execution_count": 60,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si riprova a fare apprendimento supervisionato con i dati PCA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T09:56:29.564677Z",
     "start_time": "2024-06-22T09:56:13.358509Z"
    }
   },
   "source": [
    "\n",
    "results_pca = {s: {\"decision_tree\": {\"scores\": None, \"params\": None},\n",
    "                   \"random_forest\": {\"scores\": None, \"params\": None},\n",
    "                   \"gradient_boosting\": {\"scores\": None, \"params\": None}} for s in scorings}\n",
    "\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=1)\n",
    "# TODO fonty per la grid search fa solo cv=5 che come se fosse n_repeats=1\n",
    "\n",
    "# Addestrare ogni modello per ogni metrica di scoring\n",
    "for scoring in scorings[:1]:\n",
    "    baseline_score = calculate_baseline_score(original_df, target_column, scoring)\n",
    "    print(f\"Baseline for scoring metric {scoring}: \", baseline_score)\n",
    "\n",
    "    dtr = DecisionTreeRegressor()\n",
    "    print(f\"Training decision tree with scoring metric {scoring}\")\n",
    "    results_pca[scoring][\"decision_tree\"] = search_hyperparameters(dtr, dtr_param_grid, pca_X, y, cv, scoring)\n",
    "\n",
    "    rfr = RandomForestRegressor()\n",
    "    print(f\"Training random forest with scoring metric {scoring}\")\n",
    "    results_pca[scoring][\"random_forest\"] = search_hyperparameters(rfr, rfr_param_grid, pca_X, y, cv, scoring)\n",
    "\n",
    "    gbr = GradientBoostingRegressor()\n",
    "    print(f\"Training gradient boosted model with scoring metric {scoring}\")\n",
    "    results_pca[scoring][\"gradient_boosting\"] = search_hyperparameters(gbr, gbr_param_grid, pca_X, y, cv, scoring)\n",
    "\n",
    "print(results_pca)\n"
   ],
   "execution_count": 63,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T09:56:33.698626Z",
     "start_time": "2024-06-22T09:56:33.040679Z"
    }
   },
   "source": "performance_comparison(results_pca)",
   "execution_count": 64,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T10:07:31.259961Z",
     "start_time": "2024-06-22T09:56:36.789912Z"
    }
   },
   "source": [
    "cv = RepeatedKFold(n_splits=5, n_repeats=3)\n",
    "show_learning_curves(results_pca, pca_X, y, cv)"
   ],
   "execution_count": 65,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Riassunto documentazione\n",
    "\n",
    "In questo notebook abbiamo eseguito un'analisi dei dati su un dataset di auto usate, con l'obiettivo di prevedere il prezzo di vendita di un'auto in base alle sue caratteristiche. Abbiamo eseguito un'analisi esplorativa dei dati, effettuato il preprocessing dei dati, addestrato modelli di apprendimento supervisionato e non supervisionato, e ridotto la dimensionalità dei dati utilizzando la PCA.\n",
    "\n",
    "Abbiamo confrontato le prestazioni dei modelli addestrati utilizzando diverse metriche di scoring e visualizzato le curve di apprendimento per valutare il trade-off tra bias e varianza. Infine, abbiamo esaminato l'impatto della riduzione della dimensionalità sui modelli di apprendimento supervisionato.\n",
    "\n",
    "I risultati ottenuti mostrano che i modelli di Random Forest e Gradient Boosted Trees hanno prestazioni migliori rispetto al Decision Tree, con il Gradient Boosted Trees che fornisce i risultati migliori in termini di metriche di scoring. Inoltre, la riduzione della dimensionalità tramite PCA ha portato a una riduzione delle prestazioni dei modelli di apprendimento supervisionato, con un aumento della varianza e una diminuzione della capacità predittiva.\n",
    "\n",
    "In futuro, potremmo esplorare ulteriori tecniche di preprocessing dei dati, addestrare modelli più complessi e ottimizzare ulteriormente gli iperparametri per migliorare le prestazioni dei modelli. Inoltre, potremmo esplorare altre tecniche di riduzione della dimensionalità e valutare il loro impatto sui modelli di apprendimento supervisionato."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uso della base di conoscenza nel nostro progetto\n",
    "\n",
    "Fatto macchina\n",
    "Fatto marca che collega title e marca\n",
    "\n",
    "Regola per la classe di economicità\n",
    "\n",
    "Ibrida a classe euro\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Da albero a prolog"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T16:31:13.990577Z",
     "start_time": "2024-06-21T16:31:13.938607Z"
    }
   },
   "cell_type": "code",
   "source": "dtr.fit(X, y)",
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T16:39:36.186351Z",
     "start_time": "2024-06-21T16:39:36.155183Z"
    }
   },
   "source": [
    "from sklearn.tree import _tree\n",
    "\n",
    "\n",
    "def extract_tree_structure(tree, feature_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_names = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "\n",
    "    def recurse(node, depth):\n",
    "        indent = \"  \" * depth\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_names[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            print(f\"{indent}if ({name} <= {threshold:.2f}) {{\")\n",
    "            recurse(tree_.children_left[node], depth + 1)\n",
    "            print(f\"{indent}}} else {{\")\n",
    "            recurse(tree_.children_right[node], depth + 1)\n",
    "            print(f\"{indent}}}\")\n",
    "        else:\n",
    "            print(f\"{indent}return {tree_.value[node]}\")\n",
    "\n",
    "    recurse(0, 0)\n",
    "\n",
    "\n",
    "# Extract tree structure\n",
    "def tree_to_prolog(regressor, node_id=0, parent_id=None):\n",
    "    base_code = \"\"\"\n",
    "predict(Features, Prediction) :-\n",
    "    traverse_tree(0, Features, Prediction).\n",
    "\n",
    "% Passo base\n",
    "traverse_tree(NodeID, _, Prediction) :-\n",
    "    leaf(NodeID, Prediction).\n",
    "\n",
    "% Passo ricorsivo\n",
    "traverse_tree(NodeID, Features, Prediction) :-\n",
    "    node(NodeID, FeatureIndex, Threshold, LeftChild, RightChild, _),\n",
    "    nth0(FeatureIndex, Features, FeatureValue),\n",
    "    (FeatureValue =< Threshold ->\n",
    "        traverse_tree(LeftChild, Features, Prediction)\n",
    "    ;\n",
    "        traverse_tree(RightChild, Features, Prediction)\n",
    "    ).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    result = \"\"\n",
    "    # Check if it's a leaf node\n",
    "    if regressor.tree_.children_left[node_id] == -1:\n",
    "        # Leaf node\n",
    "        value = regressor.tree_.value[node_id][0, 0]  # Assuming single target value\n",
    "        result += f\"leaf({node_id}, {value}).\\n\"\n",
    "    else:\n",
    "        # Decision node\n",
    "        feature = regressor.tree_.feature[node_id]\n",
    "        threshold = regressor.tree_.threshold[node_id]\n",
    "        left_child = regressor.tree_.children_left[node_id]\n",
    "        right_child = regressor.tree_.children_right[node_id]\n",
    "        result += f\"node({node_id}, {feature}, {threshold}, {left_child}, {right_child}, _).\\n\"\n",
    "        # Recursively add left and right children\n",
    "        result += tree_to_prolog(regressor, left_child, node_id)\n",
    "        result += tree_to_prolog(regressor, right_child, node_id)\n",
    "    return base_code + result\n",
    "\n",
    "\n",
    "prl = tree_to_prolog(dtr)\n",
    "prl = \"\\n\".join(sorted(prl.split(\"\\n\")))\n",
    "print(prl)"
   ],
   "execution_count": 33,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T16:40:00.486466Z",
     "start_time": "2024-06-21T16:40:00.478232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(list(X.iloc[0].values.astype(float)))\n",
    "dtr.predict([X.iloc[0].values])"
   ],
   "execution_count": 36,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T15:30:12.415437Z",
     "start_time": "2024-06-21T15:30:12.398110Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "execution_count": 6,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
